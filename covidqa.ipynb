{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnMNMq3eA3eFXskyXuYPY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1878042496844b38a2733716a2b12cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_835366caa979469e9efd0e345f9b815a",
              "IPY_MODEL_d6d59cf6f6bb4e6f9b1008c404834e49",
              "IPY_MODEL_1d3288c228854a5e996b7f37fba47df5"
            ],
            "layout": "IPY_MODEL_940ca9821b4844f4919461d9cc168175"
          }
        },
        "835366caa979469e9efd0e345f9b815a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04494f268494f269f22d28c47667f70",
            "placeholder": "​",
            "style": "IPY_MODEL_f5174efc0e4c441a9c6d198cc6006e07",
            "value": "100%"
          }
        },
        "d6d59cf6f6bb4e6f9b1008c404834e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d395d9a58a474799d53dc6a80129bc",
            "max": 335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19331473f01a49369bfccc280895f3fd",
            "value": 335
          }
        },
        "1d3288c228854a5e996b7f37fba47df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c8cf70ead2499896298dc4e34db3f0",
            "placeholder": "​",
            "style": "IPY_MODEL_4f06ef0b37c945149f20f98624599891",
            "value": " 335/335 [00:17&lt;00:00, 11.02ex/s]"
          }
        },
        "940ca9821b4844f4919461d9cc168175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b04494f268494f269f22d28c47667f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5174efc0e4c441a9c6d198cc6006e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d395d9a58a474799d53dc6a80129bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19331473f01a49369bfccc280895f3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5c8cf70ead2499896298dc4e34db3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f06ef0b37c945149f20f98624599891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41b66cf7daeb4ff1a3db85e9dfa8bcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abaaeb9df2a44bd1a5e703722b36baf3",
              "IPY_MODEL_1fe723e17ab0485499a0eb518a0456ef",
              "IPY_MODEL_ca74a986f72847bf9cef3a050435e5d1"
            ],
            "layout": "IPY_MODEL_28766ebd624f4a26b823a24d14ee33e1"
          }
        },
        "abaaeb9df2a44bd1a5e703722b36baf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bbebe74a0246439fc8ed6b016ffef5",
            "placeholder": "​",
            "style": "IPY_MODEL_75db09a7ad7f450ebd8b855f46da8548",
            "value": "100%"
          }
        },
        "1fe723e17ab0485499a0eb518a0456ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411fdeb9c0694ea2b11deaca34c9fed2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2f4decc015b46e1a0ba61672ffcdaaa",
            "value": 1
          }
        },
        "ca74a986f72847bf9cef3a050435e5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d459da617b2c441ba4d1321bb0bf7461",
            "placeholder": "​",
            "style": "IPY_MODEL_1930b90605eb4d219fc602301f5e1b31",
            "value": " 1/1 [00:00&lt;00:00, 21.85it/s]"
          }
        },
        "28766ebd624f4a26b823a24d14ee33e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bbebe74a0246439fc8ed6b016ffef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75db09a7ad7f450ebd8b855f46da8548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "411fdeb9c0694ea2b11deaca34c9fed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f4decc015b46e1a0ba61672ffcdaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d459da617b2c441ba4d1321bb0bf7461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1930b90605eb4d219fc602301f5e1b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrslacklines/covidqa/blob/main/covidqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1gF_CtQygk1RDUdq1IuUsvOyNSf4nWIad\" alt=\"covidqa\" width=\"200\"/>\n",
        "</center>\n",
        "\n",
        "# TL;DR\n",
        "[Do kodu](#solution)\n",
        "\n",
        "# NLP Developer - zadanie rekrutacyjne\n",
        "\n",
        "Oryginalna treść zadania:\n",
        "\n",
        "https://docs.google.com/document/d/1EgZno0N_Lggn8DTYu_kF7R0CaFr9_uoc-DhINycH_M0/edit?usp=sharing\n",
        "\n",
        "## Problem:\n",
        "Dysponujesz zbiorem dokumentów tekstowych, które chciałabyś/chciałbyś wyszukiwać za pomocą zapytań w postaci naturalnych pełnych zdań, które powiązane są z tym czego dotyczą same dokumenty. \n",
        "\n",
        "## Przykład:\n",
        "**użytkownik**: *skąd wezmę wynik testu?*\n",
        "\n",
        "**system:** (odpowiedź na pytanie: “Gdzie znajdę wynik testu?”) Informację o wyniku testu znajdziesz na Internetowym Koncie Pacjenta.(...)\n",
        "\n",
        "Przykładowy zbiór pytań i odpowiedzi:\n",
        "QA_covid - Rekrutacja NLP Deweloper\n",
        "https://docs.google.com/spreadsheets/d/1NqcXl4m5ci9QgnrMBOoQ3Nis1hwxIpg37QblVvIGhwU/edit?usp=sharing (kopia)\n",
        "\n",
        "## Twoje zadanie:\n",
        "Zaprojektuj (wybierz algorytmy, wypisz narzędzia z których byś skorzystała/skorzystał) 3 różne rozwiązania problemu.\n",
        "Zaimplementuj jedno z zaprojektowanych rozwiązań.\n",
        "\n",
        "Nie zależy nam na największej skuteczności zaimplementowanego rozwiązania, ale na tym żeby zobaczyć w jaki sposób pracujesz, jak projektujesz oraz implementujesz rozwiązania.\n",
        "\n",
        "Napisz jakie jeszcze operacje można byłoby wykonać, jakich narzędzi użyć żeby poprawić wyniki osiągnięte przez Twoją implementację.\n",
        "\n",
        "Jeżeli brakuje w zadaniu jakiś założeń - sama/sam zrób założenie i skomentuj je w notebooku. Jeżeli będziesz miała/miał jakiekolwiek pytania/wątpliwości - napisz na aleksander.obuchowski@talkie.ai\n",
        "\n",
        "Prześlij rozwiązanie w formie notebooka na Google Colab, poprosimy Cię o przedstawienie rozwiązania na naszym następnym spotkaniu.\n"
      ],
      "metadata": {
        "id": "eTUZ__oEBtZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=19XZZAygrwhG0I1Zh_cRz85s8BBXT8R9H\" alt=\"covidqa\" width=\"100\"/>\n",
        "</center>\n",
        "</br>\n",
        "\n",
        "# Przyjęte założenia:\n",
        "\n",
        "1. W przykładzie podanym w treści zadania odpowiedź systemu zawiera:\n",
        "  1. Treść pytania o najbardziej zbliżonej treści ze zbioru pytań i odpowiedzi i\n",
        "  2. pierwsze zdanie odpowiedzi.\n",
        "  \n",
        "  W tym przypadku założyłem, że opdowiedź została skrócona w celu poprawy czytelności a nie jako sugestia budowy systemu *Extractive* QA.\n",
        "\n",
        "2. Opis zadania zawiera również stwierdzenie: *Nie zależy nam na największej skuteczności zaimplementowanego rozwiązania,*\n",
        "\n",
        "  Skupiłem się raczej na rozważeniu różnych rozwiązań oraz wypisaniu możliwych usprawnień oraz ich wad i zalet niż na fine tuningu-modelu.\n",
        "\n",
        "3. Brak wzmianek o konieczności formalnej ewaluacji modelu oraz założenie 2. przyjąłem dosłownie i potraktowałem to z najniższym priorytetem (opcjonalnie), mając pełną świadomość popełnianego błedu w sztuce.\n",
        "\n",
        "4. Założyłem, że zależy nam na jak najszybszym rozwiązaniu problemu biznesowego i dostarczenie względnie użytecznego MVP, którego użytkownikiem końcowym będzie np. gość portalu e-Pacjent lub podobnego, który szuka odpowiedzi na typowe pytanie dotyczące wirusa. Założyłem też, że jesteśmy w trakcie trwania pandemii i pytania będą adekwatne do zbioru, który stanowi bazę dokumentów w tym zadaniu. Czyl będą to np. pytania \"Czy maseczki chronią przed zakażeniem\"."
      ],
      "metadata": {
        "id": "uh5E7F8OCrg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=19XZZAygrwhG0I1Zh_cRz85s8BBXT8R9H\" alt=\"covidqa\" width=\"100\"/>\n",
        "</center>\n",
        "</br>\n",
        "\n",
        "# Rozwiązania\n",
        "\n",
        "Dostępne rozwiązania można podzielić na:\n",
        "- rozwiązania oparte o symboliczną reprezentację wiedzy,\n",
        "- metody oparte o wyszukiwanie w przestrzeni wektorów cech:\n",
        "  - oparte o klasyczne nielingwistyczne metody reprezentacji dokumentów (BOW, TFIDF),\n",
        "  - oparte o reprezentację dokumentów za pomocą sieci neuronowych (embeddings), (doc2vec, transformers, sentence transformers),\n",
        "- metody generatywne oparte o głębokie sieci neuronowe.\n",
        "\n",
        "Granica pomiędzy tymi typami rozwiązań jest umowna i jest to raczej kontinuum technik, które stosowane są wybiórczo w zależności od natury problemu. Dlatego należałoby rozpatrzyć trzecią kategorię, czyli:\n",
        "\n",
        "- Rozwiązania hybrydowe, łączące cechy pozostałych.\n",
        "\n",
        "Rozpatrując możliwe rozwiązania pominiemy też ostatni typ, czyli w pełni generatywne modele oparte o głębokie sieci neuronowe. Są to metody, które praktycznie zawsze wymagają uczenia. W naszym przypadku dysponujemy bardzo małym zbiorem danych. Można by oczywiście pokusić się o generowanie próbek syntetycznych czy inne metody ale jest to rozwiązanie ryzykowne, które prawdopodobnie nie pozwoliło by szybko osiągnąć akceptowalnych rezultatów.\n",
        "\n",
        "Skupimy się głównie na metodach wyszukiwawczych. W tym przypadku zwykle dysponujemy jakąś bazą wiedzy jak np. nasz zbiór FAQ, w którym wyszukiwane są odpowiedzi na pytania. Wyszukiwanie może odbywać na zasadzie próby odnalezienia (1) podobnych pytań w bazie lub (2) odpowiedzi pasujących do pytania. Mówimy wtedy o wyszukiwaniu symetrycznym lub asymetrycznym. Ja skupię się na rozwiązaniach symetrycznych, czyli będę starał się odnaleźć jak najbardziej podobne pytanie w naszej bazie. Przetestowanie działania wyszukiwania asymetrycznego jest oczywiście kuszące ale z braku czasu musimy je pominąć.\n",
        "\n",
        "Zacznę jednak od krótkiego omówienia rozwiązania czysto lingwistycznego (w końcu nie mógłbym sobie tego podarować :)) żeby mieć to z głowy i móc przejść do rozwiązań czysto pragmatycznych.\n",
        "\n",
        "</br>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=19XZZAygrwhG0I1Zh_cRz85s8BBXT8R9H\" alt=\"covidqa\" width=\"100\"/>\n",
        "</center>\n",
        "</br>\n",
        "\n",
        "## Rozwiązanie oparte o symboliczną reprezentację wiedzy (1)\n",
        "\n",
        "W niektórych przypadkach opłaca się zbudować specjalną symboliczną reprezentację wiedzy zawartej w dostępnych dokumentach. W tym celu wykorzystuje się szereg metod z zakresu *klasycznego*, które służą do ekstrakcji wiedzy i stanowią też inwentarz narzędzi Information Retrievalowych, np. wykrywanie bytów nazwanych i parsing zależnościowy.\n",
        "\n",
        "Informacje te wykorzystywane są do ekstrakcji wiedzy i jej zapisu np. za pomocą jakiegoś języka logiki; rachunku predykatów, logiki modalnej i temporalnej. Mogą to też być np. trójki (*triplets*) Object Attribute Value, sieci semantyczne podobne do Wordnetu tylko oparte o inne interesujące nas relacje, czy też specjalnie zaprojektowane struktury danych/formalizmy takie jak ramy semantyczne (np. CxG) czy ontologie.\n",
        "\n",
        "Ważnym elementem tak wdrożonego rozwiązania jest też przetwarzanie samych pytań na podstawie różnego rodzaju taxonomii. Także tutaj dostępne są różne rozwiązania i formalizmy, jednak cel we wszystkich przypadkach jest taki sam -- wykrycie i formalna reprezentacja typu pytania i rodzaju odpowiedzi (np. \"Czy Sokrates jest ateńczykiem?\" `-> ENTITY|PERSON|BIRTHPLACE`).\n",
        "\n",
        "Po otrzymaniu i przetworzeniu pytania system stara się wyłonić kandydatów wśród dokumentów/rekordów w bazie wiedzy.\n",
        "\n",
        "### Zalety i wady\n",
        "Jak widać już na pierwszy rzut oka to rozwiązanie wymaga bardzo dużych nakładów czasu oraz mozolnej pracy, mimo tego, że możliwa jest oczywiście częściowa automatyzacja budowy bazy wiedzy oraz zaprzężenie technik neuralnych do całego procesu.\n",
        "Symboliczna oraz regułowa natura reprezentacji wiedzy oraz sposobu jej przetwarzania sprawia, że gotowy system jest w pełni *wyjaśnialny* (*explainable*) ale jest on też niezbyt elastyczny i posiada bardzo ograniczone możliwości generalizacji.\n",
        "\n",
        "### Technologie\n",
        "\n",
        "Ilość narzędzi i zasobów do symbolicznego przetwarzania języka polskiego jest wbrew pozorom całkiem spora. Zespół badaczy z ZIL IPI PANu oraz projektu CLARIN a także wielu pokrewnych projektów i grup badawczych udostępnia je na otwartych licencjach (co może być zarówno ich wadą jak i zaletą).\n",
        "\n",
        "http://clarin-pl.eu\n",
        "\n",
        "http://zil.ipipan.waw.pl\n",
        "\n",
        "Warto tutaj wymienić:\n",
        "- Polski Wordnet\n",
        "- Morfeusz\n",
        "- Concraft\n",
        "- Polish Dependency Parsing i polski Treebank\n",
        "- NLTK, SpaCy\n",
        "\n",
        "Myślę, że gdyby było więcej czasu można by pokusić się o zbudowanie prototypu w oparciu o te narzędzia, do reprezentacji wiedzy wykorzystując triplety OAV i dowolny framework do rozwoju gramatyk, np. Grammatical Framework.\n",
        "Wartość takiego rozwiązania dla bieżącego problemu oceniam jednak dość nisko. Było by ono na pewno ciekawe z badawczego punktu widzenia :)\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=19XZZAygrwhG0I1Zh_cRz85s8BBXT8R9H\" alt=\"covidqa\" width=\"100\"/>\n",
        "</center>\n",
        "\n",
        "\n",
        "## Rozwiązania oparte o wyszukiwanie w przestrzeni wektorów cech\n",
        "\n",
        "## Wyszukiwanie oparte o TF-IDF (2)\n",
        "\n",
        "Kolejna klasa możliwych rozwiązań opiera się o algorytmy używane w klasycznym przetwarzaniu tekstu. Stosują one popularne od wielu lat metody parametryzacji dokumentów tekstowych za pomocą zliczania częstotliwości występujących w nich słów. Stosuje się tu szereg metod, również core'owych metod NLP. W przypadku syntetycznego (fleksyjnego) języka polskiego opłacalne jest bowiem sprowadzenie słów do form podstawowych. Można to zrobić metodą *płytką* poprzez stemming lub *głęboką* za pomocą lemmatyzacji. W ten sposób nie będziemy zliczać wszystkich występujących w dokumentach form osobno, zaoszczędzimy pamięć, zmniejszymy rozmiar finalnego wektora i na pewno poprawimy wyniki. Dodatkowo, okazuje się, że warto odfiltrować tzw. *stopwords*. Są to słowa bardzo częste niosące bardzo małe znaczenie jak np. zaimki osobowe, przyimki itd. (ilokroć to piszę robi mi się słabo, jako językoznawcy, bo np. zaimek osobowy \"ja\" jest przedmiotem dyskusji filozofów i myślicieli od tysięcy lat, no ale nie o tym.. :)).\n",
        "Na tej podstawie możemy najzwyczajniej zliczyć wystąpienia wszystkich słów z naszego *vocabulary* w każdym dokumencie (bag-of-words) i przedstawić to jako wektor rzadki. Usprawnienie może być użycie n-gramów, które umożliwią nam reprezentację lokalnego (bezpośredniego) konktekstu i stanowią bardzo proste ale potężne ulepszenie. Tutaj oczywiście pojawia się problem związany z małą ilościa przykładów i wielkim rozmiarem wektora cech.\n",
        "Kolejną modyfikacją tej metody jest zastosowanie parametryzacji poprzez wyliczenie TF-IDF (Text Frequency - Inverse Document Frequency). W tym przypadku ważymy słowa występujące w danym dokumencie przez pryzmat ich ogólnej częstości we wszystkich dokumentach. W ten prosty sposób możemy otrzymać reprezentację wektorową, która reprezentuje słowa charakterystyczne dla danego dokumentu w kontekście frekwencji w całym naszym zbiorze. Tutaj też możemy wykorzystać nie tylko pojedyncze słowa ale i n-gramy.\n",
        "Tak przygotowaną reprezentację wektorową można wykorzystać do bardzo efektywnego wyszukiwania za pomocą miar odległości euklidesowej, podobieństwa cosinusowego czy np. miary Jaccarda. Przechowując takie reprezentacje tekstu w bazie wektorowej, która dodatkowo umożliwia wykonywanie kwerend w oparciu o te miary jest bardzo efektywne i może zostać bardzo szybko zdeployowane w postaci bardzo taniego i wysokoskalowalnego rozwiązania chmurowego (np. serverless)\n",
        "Takie właśnie klasyczne rozwiązanie naszego problemu (bez cloud deploymentu :)) zaimplementujemy jako benchmark, z którym porównamy metody oparte o reprezentacje wektorowe generowane przez najlepsze sieci neuronowe.\n",
        "\n",
        "### Zalety i wady\n",
        "Rozwiązanie to jest bardzo proste i szybkie do zaimplementowania. To w zasadzie dwie linijki w SKLearn. Jest ono bardzo łatwo *wyjaśnialne* oraz bardzo elastyczne. Posiada bardzo dużą zdolność generalizowania. Co prawda wyliczanie TF-IDF jest dość wolne ale przy infrastrukturze i zasobach, której wymaga współczesny deep learning, myślę, że to już trochę wstyd o tym wspominać.\n",
        "Najwiekszą wadą tego rozwiązania jest ograniczona możliwość reprezentacji znaczenia. Jest ona minimalna bo zawęża się tylko do bezpośredniego kontekstu (i to w najlepszym wypadku).\n",
        "\n",
        "### Technologie\n",
        "\n",
        "- SKLearn\n",
        "- SpaCy\n",
        "- NLTK\n",
        "\n",
        "## Wyszukiwanie semantyczne oparte o Sentence Embeddings (3)\n",
        "\n",
        "Na drugim biegunie znajdują się rozwiązania oparte o głebokie sieci neuronowe. Stosuje się tutaj w zasadzie wszystkie architektury takie jak rekurencyjne sieci neuronowe (RNN), które do pewnego momentu stanowiły standard *de facto* dla problemów związanych z przetwarzaniem języka, sieci LSTM czy sieci CNN.\n",
        "Występują one w różnorodnych konfiguracjach np. jako sieci syjamskie.\n",
        "\n",
        "Jeżeli chodzi o klasyczny *representation learning* trzeba oczywiście koniecznie wspomnieć o Gensim Word2Vec i wszystkich jego następcach i odmianach jak Doc2Vec, Sent2Vec czy np. Graph2Vec. Oryginalny Gensim to w zasadzie dwa modele, stanowiące niejako swoje lustrzane odbicie; Skip-Gram oraz Continuous Bag Of Words.\n",
        "\n",
        "W 2023 roku trudno jednak pominąć sieci typu Transformer i opartych o te architektury Pretrained Large Language Models (PLLMs). Podobnie jak Doc2Vec pozwalają one wygenerować parametryczną reprezantację dokumentu tekstowego w postaci *gęstego* wektora. Charakter tych modeli sprawia, że taki w zasadzie dość nieduży (np. 768) wektor w zaskakujący sposób oddaje charakter języka i kontekstualne (distrybucyjne) znaczenie słów lub innych tokenów.\n",
        "\n",
        "Taka reprezentacja dokumentów umożliwia ich wyszukiwanie i porównywanie za pomocą tych samych miar jak w przypadku rozwiązania opartego o TF-IDF.\n",
        "\n",
        "**Poniżej, jako rozwiązanie zadania, znajduje się prosta implementacja metody opartej o Sentence-Transformers, indeksowanie FAISS i badania podobieństwa cosinusowego**\n",
        "[Do kodu](#solution)\n",
        "\n",
        "### Zalety i wady\n",
        "Jest to chyba najdynamiczniej rozwijająca się dziedzina Machine Learningu. Powstało i wciąż powstaje wiele wspaniałych bibliotek oraz publicznie dostępnych modeli. Jednym z najważniejszych ekosystemów jest HuggingFace. Oczywiście język polski jest jak zwykle lekko z tyłu i chociaż istnieją wytrenowane modele oparte o te najpopularniejsze architektury to daleko im do tych dla języka angielskiego czy chińskiego. Modele te są zwykle bardzo duże, koszt ich treningu jest wielki. Jesteśmy więc zdani na to co jest dostępne.\n",
        "Transfer learning otwiera przed nami zupełnie nowe możliwości. Możemy wykorzystać core polskiego HerBerta wytrenowanego na MLM i dodać mu *HEAD* np. do QuestionAnsweringu, który będzie wymagał tylko małego dotrenowania i uzyskamy potężne rozwiązanie stosunkowo małym kosztem.\n",
        "Zarówno wad i zalet jest tutaj bardzo dużo i trudno wyczerpać temat w ramach kilku zdań.\n",
        "\n",
        "### Technologie\n",
        "\n",
        "- HuggingFace\n",
        "\n",
        "## Usprawnienia (+ 4 rozwiązanie :))\n",
        "\n",
        "Ponieważ i tak już jest zbyt dużo tekstu to wymienie potencjalne usprawnienia w formie punktów. Ostatnie z nich można potraktować jako 4 dodatkowy sposób rozwiązania problemu.\n",
        "\n",
        "- Rozwijanie zapytań poprzez parafrazę\n",
        "- Dodanie modułu rule-based dla najbardziej typowych pytań, np. w oparciu o słowa kluczowe albo nawet RegExpy\n",
        "- Post-processing zwracanych odpowiedzi\n",
        "- Wyłanianie n-kandydatów i dodatkowy algorytm do ratingu kandydatów\n",
        "- Rozwój metody do ewaluacji algorytmu (uważam, że jego brak jest największym pain pointem)\n",
        "- Fajnie było by zrobić mini grid search przez różne modele i miary podobieństwa/odległości jak:\n",
        "  - Podobieństwo cosinusowe,\n",
        "  - Euclidean distance\n",
        "  - Jaccard Index\n",
        "- Można by pokusić się o próbę transfer learningu jakiegoś z dostępnych modeli. Może mógłby to być model domenowy (BioMed) albo model typowo QuestionAnsweringowy?\n",
        "- Widziałem też rozwiązanie dla francuskiego, w którym wykorzystano model dla języka angielskiego w połączeniu z modelem do tłumaczenia maszynowego.\n",
        "- Jest trochę angielskich datasetów dla Covid19 i/lub dla Biomed QA. Może udałoby się uzyskać ciekawe rezultaty tłumacząc taki dataset automatycznie na polski i wyuczając na nim jakiś model.\n",
        "- Są też różne datasety QA dla polskiego a nawet framework testowy KLEJ, którym nie poświęciłem należytej uwagi.\n",
        "- **Rozwiązanie 4**: Zbudowanie kilku modeli w oparciu o różne metody oraz modele (np. TFIDF, Doc2Vec, BERT, SentenceBert itp.) i zestackowanie ich w ramach jednego algorytmu. Na końcu można by wykorzystać nawet tak proste rozwiązanie jak głosowanie większościowe. Kilka słabych modeli razem jest lepsze niż najlepszy z nich osobno. Można by pokusić się też o Metalearnera na końcu tego stacku, sieci syjamskie, tyle tego jest.. :)"
      ],
      "metadata": {
        "id": "irxT3mbyI60i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"solution\"></a>\n",
        "# Rozwiązanie oparte o Semantic Search na podstawie Sentence Embeddings\n",
        "\n",
        "To rozwiązanie wydało mi się najbardziej sensowne ponieważ:\n",
        "\n",
        "1. Pozwala szybko uzyskać względnie dobre rezultaty\n",
        "2. Było łatwe do zaimplementowania dzięki wykorzystaniu HuggingFace\n",
        "3. Dostępne modele dla polskiego są wystarczające dla tego rozwiązania, jest ich kilka i można było je łatwo przetestować\n",
        "4. Treść zadania nie narzuca budowy systemu typu Generative QA czy nawet Extractive QA."
      ],
      "metadata": {
        "id": "7uMOO1KIidWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Korzystam głównie z HuggingFace Transformers. Instaluję biblioteki, którymi się posługiwałem."
      ],
      "metadata": {
        "id": "fYktYBODkbNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate sentence_transformers datasets faiss-gpu\n",
        "!python -m spacy download pl_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqQ2kDIjpUay",
        "outputId": "3f6292aa-2b4a-4444-e98a-532ed1f989b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.16.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.8/dist-packages (2.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.8/dist-packages (1.7.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "2023-02-20 19:24:18.190765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-20 19:24:20.077762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-20 19:24:20.077914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-20 19:24:20.077950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pl-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.4.0/pl_core_news_sm-3.4.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from pl-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (8.1.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (1.10.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->pl-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: pl-core-news-sm\n",
            "Successfully installed pl-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importuję zainstalowane biblioteki."
      ],
      "metadata": {
        "id": "2uM4lb-3Hu0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F9_zqvonI9d8"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutaj definiuję kilka *globalny stałych* (zmiennych), tak żeby nie hardcodować np. ścieżki do pliku z danymi czy nazwy checkpointa HF."
      ],
      "metadata": {
        "id": "6Nq3xQscHz5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILENAME = \"QA_covid - Rekrutacja NLP Deweloper\"\n",
        "SHEET_NAME = \"q_a (1)\"\n",
        "MODEL_CHECKPOINT = \"Voicelab/sbert-large-cased-pl\"\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "XenN8FzpKZvw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loguje się do Google Drive gdzie zapisałem arkusz z pytaniami i odpowiedziami."
      ],
      "metadata": {
        "id": "qkYlVtT2IF1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "5dVgAf9GLD2n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dzieki temu mogę w kilku linijkach kodu odczytać arkusz prosto z chmury i wczytać go jako DataFrame Pandas."
      ],
      "metadata": {
        "id": "ZfEyqZhGIPJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet = gc.open(DATA_FILENAME).sheet1\n",
        "\n",
        "df = pd.DataFrame.from_records(worksheet.get_all_values())\n",
        "df.columns = df.iloc[0]\n",
        "df.drop(index=0, inplace=True)\n",
        "df_backup = df.copy()\n",
        "df"
      ],
      "metadata": {
        "id": "Xyv0w6tjKNwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3d02cf32-7b04-43a5-ae45-25c3df46a037"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                    Q  \\\n",
              "1    Jakie objawy są charakterystyczne dla koronawi...   \n",
              "2    Co zrobić w przypadku wystąpienia duszności i ...   \n",
              "3    Mam objawy charakterystyczne dla COVID-19. Co ...   \n",
              "4    Nie mogę skontaktować się ze swoim lekarzem PO...   \n",
              "5    Mój lekarz POZ nie dyżuruje, a ja mam objawy C...   \n",
              "..                                                 ...   \n",
              "331  Czy regularne płukanie nosa solą fizjologiczną...   \n",
              "332  Czy jedzenie czosnku może zapobiec infekcji no...   \n",
              "333  Czy zimna pogoda i śnieg mogą zabić koronawirusa?   \n",
              "334  Czy osoba która umiera na COVID podlega kremacji?   \n",
              "335                             Kto może oddać osocze?   \n",
              "\n",
              "0                                                    A  \n",
              "1    Osoby zakażone koronawirusem zwykle mają:wysok...  \n",
              "2    Jeżeli występują u ciebie duszności lub kłopot...  \n",
              "3    Jeśli Twoje objawy są typowe dla zakażenia kor...  \n",
              "4    Jeśli nie możesz skontaktować się ze swoim lek...  \n",
              "5    Jeśli lekarz wybrany przez Ciebie jako lekarz ...  \n",
              "..                                                 ...  \n",
              "331  Nie. Nie ma dowodów na to, że regularne płukan...  \n",
              "332  Czosnek to zdrowa żywność, która może mieć pew...  \n",
              "333  Nie ma powodu sądzić, że zimna pogoda może zab...  \n",
              "334    Nie ma obowiązku kremacji zmarłych na COVID-19.  \n",
              "335  Osocze może zostać pobrane od osób:w wieku 18 ...  \n",
              "\n",
              "[335 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab1244cc-7c46-44e2-b3f7-8f2a256c246f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jakie objawy są charakterystyczne dla koronawi...</td>\n",
              "      <td>Osoby zakażone koronawirusem zwykle mają:wysok...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Co zrobić w przypadku wystąpienia duszności i ...</td>\n",
              "      <td>Jeżeli występują u ciebie duszności lub kłopot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mam objawy charakterystyczne dla COVID-19. Co ...</td>\n",
              "      <td>Jeśli Twoje objawy są typowe dla zakażenia kor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nie mogę skontaktować się ze swoim lekarzem PO...</td>\n",
              "      <td>Jeśli nie możesz skontaktować się ze swoim lek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mój lekarz POZ nie dyżuruje, a ja mam objawy C...</td>\n",
              "      <td>Jeśli lekarz wybrany przez Ciebie jako lekarz ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>Czy regularne płukanie nosa solą fizjologiczną...</td>\n",
              "      <td>Nie. Nie ma dowodów na to, że regularne płukan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>Czy jedzenie czosnku może zapobiec infekcji no...</td>\n",
              "      <td>Czosnek to zdrowa żywność, która może mieć pew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>Czy zimna pogoda i śnieg mogą zabić koronawirusa?</td>\n",
              "      <td>Nie ma powodu sądzić, że zimna pogoda może zab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>Czy osoba która umiera na COVID podlega kremacji?</td>\n",
              "      <td>Nie ma obowiązku kremacji zmarłych na COVID-19.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>Kto może oddać osocze?</td>\n",
              "      <td>Osocze może zostać pobrane od osób:w wieku 18 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>335 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab1244cc-7c46-44e2-b3f7-8f2a256c246f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab1244cc-7c46-44e2-b3f7-8f2a256c246f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab1244cc-7c46-44e2-b3f7-8f2a256c246f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jeżeli chcielibyśmy np. fine tune'ować model łatwo da się też przekonwertować dane do postaci Datasetu HuggingFace, który też udostępnia ograniczone API do transformacji danych (np. metodę `map()`) "
      ],
      "metadata": {
        "id": "wCCWWlipIbJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5RcQV6im_M0",
        "outputId": "52cdc485-3555-479a-a4f0-0735626b6532"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Q', 'A', '__index_level_0__'],\n",
              "    num_rows: 335\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutaj wykorzystuję bardzo przydatne API HuggingFace w klasach `AutoModel` i `AutoTokenizer`, które bardzo przyśpieszają prototypowanie i eksperymenty z różnymi checkpointami i architekturami modeli. HF jest w stanie automatycznie wykryć architekturę modelu i go zainicjować. Dostępne są też klasy typu `AutoModelFor*` np. `AutoModelForQuestionAnswering`, które wykorzystują core dowolnego modelu i dodają do niego automatycznie wygenerowany *Head* dla konkretnego zadania. W naszym przypadku nie jest to koniecznie bo będzie wykorzystywali tylko enkoder do budowy reprezentacji semantycznej tekstu. Wykorzystany tutaj model to SentenceBert. Pod spodem HF wykorzystuje specjalną libkę Sentence-Bert https://www.sbert.net/docs/usage/semantic_textual_similarity.html. W pierwszej iteracji tego rozwiązania też z niej korzystałem ale uznałem, że nie ma sensu utrudniać sobie życia :) Swoją drogą w trakcie przygotowywania się do realizacji tego zadania zrobiłem kurs HuggingFace Transformers i stałem się wielkim fanem :)\n",
        "W ostatnim kroku ładujemy model do GPU bo szanujemy swój czas."
      ],
      "metadata": {
        "id": "2uW8ipeS6BgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "model = AutoModel.from_pretrained(MODEL_CHECKPOINT)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtk6AfIGoVIp",
        "outputId": "9c261cbf-9f6b-481d-9b6b-592953df04a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(50000, 1024, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiujemy sobie funkcję pomocniczą do *poolowania* i do parametryzacji tekstu pod postacią embeddingsów."
      ],
      "metadata": {
        "id": "MI-c0Qo-uqnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_pooling(model_output):\n",
        "    return model_output.last_hidden_state[:, 0]"
      ],
      "metadata": {
        "id": "xMlRhx6XAPnd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text_list):\n",
        "    encoded_input = tokenizer(\n",
        "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
        "    model_output = model(**encoded_input)\n",
        "    return cls_pooling(model_output)"
      ],
      "metadata": {
        "id": "tCEukDcbsXYr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generujemy sobie dataset pod postacią samych embeddingsów i dodajemy index FAISS (korzystałem kiedyś z niego w projekcie z rozpoznawaniem twarzy). W przypadku budowy prawdziwego rozwiązania można w ramach optymalizacji należało by to było wrzucić do bazy danych, która:\n",
        "- wspiera taki format danych (wektory)\n",
        "- implementuje podobieństwo cosinusowe lub inną podobną miarę jako operację za pomocą, której możemy wyszukiwać rekordy."
      ],
      "metadata": {
        "id": "Gimfe1yAK1fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dataset = ds.map(\n",
        "    lambda x: {\"embeddings\": get_embeddings(x[\"Q\"]).detach().cpu().numpy()[0]}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1878042496844b38a2733716a2b12cc0",
            "835366caa979469e9efd0e345f9b815a",
            "d6d59cf6f6bb4e6f9b1008c404834e49",
            "1d3288c228854a5e996b7f37fba47df5",
            "940ca9821b4844f4919461d9cc168175",
            "b04494f268494f269f22d28c47667f70",
            "f5174efc0e4c441a9c6d198cc6006e07",
            "d4d395d9a58a474799d53dc6a80129bc",
            "19331473f01a49369bfccc280895f3fd",
            "c5c8cf70ead2499896298dc4e34db3f0",
            "4f06ef0b37c945149f20f98624599891"
          ]
        },
        "id": "28JcVXYEsiLF",
        "outputId": "912ee516-70e8-4034-9ed8-02d331466e20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/335 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1878042496844b38a2733716a2b12cc0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "41b66cf7daeb4ff1a3db85e9dfa8bcfa",
            "abaaeb9df2a44bd1a5e703722b36baf3",
            "1fe723e17ab0485499a0eb518a0456ef",
            "ca74a986f72847bf9cef3a050435e5d1",
            "28766ebd624f4a26b823a24d14ee33e1",
            "44bbebe74a0246439fc8ed6b016ffef5",
            "75db09a7ad7f450ebd8b855f46da8548",
            "411fdeb9c0694ea2b11deaca34c9fed2",
            "d2f4decc015b46e1a0ba61672ffcdaaa",
            "d459da617b2c441ba4d1321bb0bf7461",
            "1930b90605eb4d219fc602301f5e1b31"
          ]
        },
        "id": "3FtvZRIdvbDf",
        "outputId": "68569089-40c7-4531-dc9e-a97eece60c0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41b66cf7daeb4ff1a3db85e9dfa8bcfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Q', 'A', '__index_level_0__', 'embeddings'],\n",
              "    num_rows: 335\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Możemy już sprawdzić jak działa wyjściowy system."
      ],
      "metadata": {
        "id": "dNPRDclMLnK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wpisz pytanie\n",
        "question = 'Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu si\\u0119 koronawirusa?' #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ELVUsmwPAumk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgweGV4py6WE",
        "outputId": "63908ec8-ba0b-4a04-eebf-5f284e57e606"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu się koronawirusa?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jak widać system dość dobrze radzi sobie ze znalezieniem podobnych pytań w bazie na poziomie słownictwa - niestety nie zawsze oznacza to znalezienie najbardziej odpowiedniej odpowiedzi na zadane pytanie."
      ],
      "metadata": {
        "id": "H5vZ_k7PLyBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_answer(question, matched_db_question, answer):\n",
        "  print(f\"INPUT QUESTION: {question}\")\n",
        "  print(f\"MATCHED DB QUESTION: {matched_db_question}\")\n",
        "  print(f\"ANSWER: {answer}\")"
      ],
      "metadata": {
        "id": "7vMfUDx1bAV5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
        "\n",
        "scores, samples = embeddings_dataset.get_nearest_examples(\n",
        "    \"embeddings\", question_embedding, k=5\n",
        ")\n",
        "samples_df = pd.DataFrame.from_dict(samples)\n",
        "samples_df[\"scores\"] = scores\n",
        "samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n",
        "\n",
        "best_ans = samples_df.iloc[0]\n",
        "\n",
        "print_answer(question, best_ans.Q, best_ans.A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja9pP9D4Bzwh",
        "outputId": "5531ff55-7bf9-423f-ab17-edc2f730d817"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT QUESTION: Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu się koronawirusa?\n",
            "MATCHED DB QUESTION: Czy lampa dezynfekująca na promienie UV może zabić nowego koronawirusa?\n",
            "ANSWER: Lampy UV przeznaczone są do dezynfekcji pomieszczeń, nie powinny być używane do sterylizacji rąk lub innych obszarów skóry, ponieważ promieniowanie UV może powodować podrażnienie skóry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dla zabawy możemy też zobaczyć jak poradziłby sobie model do ekstraktywnego QA:"
      ],
      "metadata": {
        "id": "LDsVh85jMFlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "extractive_qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"henryk/bert-base-multilingual-cased-finetuned-polish-squad2\",\n",
        "    tokenizer=\"henryk/bert-base-multilingual-cased-finetuned-polish-squad2\"\n",
        ")"
      ],
      "metadata": {
        "id": "xS8nHX5u14bS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = best_ans.A"
      ],
      "metadata": {
        "id": "Tn-YZnmb27CE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kipoMi4rMQx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extr_ans = extractive_qa_pipeline(\n",
        "    {\n",
        "        'context': context,\n",
        "        'question': question\n",
        "     }\n",
        ")\n",
        "\n",
        "print_answer(question, context, extr_ans.get('answer', '???'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAldjPO94gdh",
        "outputId": "6cf5b7ba-9317-4017-e472-95ca1463b7f7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT QUESTION: Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu się koronawirusa?\n",
            "MATCHED DB QUESTION: Nie ma powodu sądzić, że zimna pogoda może zabić koronawirusa lub inne choroby. Normalna temperatura ciała człowieka wynosi około 36,5 stopni C do 37 stopni C, niezależnie od temperatury zewnętrznej i pogody. Najskuteczniejszym sposobem ochrony przed nowym koronawirusem jest częste mycie rąk wodą i mydłem oraz korzystanie środków do dezynfekcji rąk na bazie alkoholu . Należy także unikać bliskiego kontaktu z każdym, kto kaszle i kicha.\n",
            "ANSWER: zimna pogoda może zabić koronawirusa lub inne choroby.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nie dysponujemy niestety żadnym zbiorem testowym, na którym można by przetestować działanie naszego rozwiązania. Pozostaje nam ręczne testowanie i trochę pośrednich miar, które można by wyliczyć.\n",
        "\n",
        "Zapomnieliśmy jednak o najważniejszym kroku, od którego powinniśmy zacząć. Za bardzo poniosły nas emocje i nie zbudowaliśmy prostego modelu, który mógłby stanowić nasz benchmark. Zrobimy to teraz.\n",
        "\n",
        "W tym celu użyję miary TF-IDF, na podstawie której zbudujemy wektor cech składający się z frekwencji słów kluczowych każdego dokumentu. Następnie wykorzystamy te wektory w ten sam sposób jak poprzednio - będziemy wyszukiwali podobne pytania za pomocą np. podobieństwa cosinusowego."
      ],
      "metadata": {
        "id": "xaxxnfZTMdNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.pl.examples import sentences \n",
        "\n",
        "nlp = spacy.load(\"pl_core_news_sm\")\n",
        "\n",
        "# Usuwamy niepotrzebne elementy pipeline'u\n",
        "print(\"Pipeline NLP SpaCy\")\n",
        "print(\"Przed: \", \", \".join(nlp.pipe_names))\n",
        "for proc_step in [\"parser\", \"attribute_ruler\", \"ner\"]:\n",
        "  nlp.remove_pipe(proc_step)\n",
        "print(\"Po: \", \", \".join(nlp.pipe_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHJ_slyHQ0fy",
        "outputId": "47d68f82-9fe2-427e-fd77-8692c9d1ccee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline NLP SpaCy\n",
            "Przed:  tok2vec, morphologizer, parser, lemmatizer, tagger, attribute_ruler, ner\n",
            "Po:  tok2vec, morphologizer, lemmatizer, tagger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "  return [tok.lemma_ for tok in nlp(doc) if not tok.is_stop and not tok.is_punct]"
      ],
      "metadata": {
        "id": "6E1SqgJHXXYF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Q_preprocessed\"] = df[\"Q\"].apply(preprocess)\n",
        "df[\"Q_preprocessed\"].values[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_DPCSJoXaik",
        "outputId": "e55277e3-4a69-4c33-bc30-7508f917b50e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['objaw', 'charakterystyczny', 'koronawiruso']),\n",
              "       list(['zrobić', 'przypadek', 'wystąpić', 'duszność', 'trudność', 'oddychanie']),\n",
              "       list(['objaw', 'charakterystyczny', 'COVID', '19', 'powinien być', 'zrobić', 'pierwszy', 'kolejność']),\n",
              "       list(['móc', 'skontaktować', 'swój', 'lekarz', 'POZ', 'zrobić']),\n",
              "       list(['lekarz', 'POZ', 'dyżurować', 'objawy', 'COVID', '19', 'zrobić']),\n",
              "       list(['skierować', 'test', 'wystawić', 'lekarz', 'POZ', 'lekarz', 'nocny', 'świąteczny', 'telepomoc', 'wystawić', 'skierowanie']),\n",
              "       list(['znaleźć', 'wynik', 'test']),\n",
              "       list(['wynik', 'test', 'pozytywny', 'zostana', 'poinformować']),\n",
              "       list(['skontaktować być', 'sanepidem', 'pomoc', 'formularz', 'strona', 'dostać', 'odpowiedź', 'pytanie']),\n",
              "       list(['znaczyć', 'mieć być', 'bliski', 'kontakt', 'osoba', 'chory']),\n",
              "       list(['mieć być', 'bliski', 'kontakt', 'osoba', 'otrzymać', 'pozytywny', 'wynik', 'test', 'powinien być', 'zgłosić']),\n",
              "       list(['dostać', 'informacja', 'zostać być', 'objąć', 'kwarantanna', 'zgłoszeć', 'bliskiy', 'kontakt', 'osoba', 'zarażony']),\n",
              "       list(['mieć być', 'bliski', 'kontakt', 'osoba', 'chory', 'dostać być', 'informacja', 'zostać być', 'objąć', 'kwarantanna', 'znaczyć', 'móc', 'iść', 'praca', 'sklep']),\n",
              "       list(['kwarantann', 'domownik', 'musieć', 'przebywać']),\n",
              "       list(['móc', 'otrzymać', 'informacja', 'temat', 'kwarantanny']),\n",
              "       list(['ozdrowieniec', 'podlegać', 'kwarantannie', 'kontakt', 'osoba', 'chory']),\n",
              "       list(['osoba', 'zaszczepić', 'COVID', '19', 'kierować', 'kwarantanna', 'kontakt', 'osoba', 'zakażić', 'koronawirus']),\n",
              "       list(['muy', 'mieć', 'skierować', 'test', 'przygotować', 'móc', 'wykonać']),\n",
              "       list(['skierować', 'test', 'COVID', '19']),\n",
              "       list(['rodzaj', 'test', 'zwalniać', 'obowiązkowy', 'kwarantanna', 'przyjazd', 'Polska', 'należeć', 'wykonać', '\\xa0'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Pomijamy wbudowany preprocesor i użyjemy uni- i bigramów żeby oszukać i przemycić trochę semantyki dystrybucyjnej ;)\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), tokenizer=preprocess, stop_words=None, lowercase=False)    \n",
        "tfidf_docs_arr = tfidf.fit_transform(df[\"Q\"])"
      ],
      "metadata": {
        "id": "iKEZeG9qMchv"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Możemy sprawdzić czy nasz `TfidfVectorizer` zadziałał jak trzeba sprawdzając vocabulary."
      ],
      "metadata": {
        "id": "rTQN99c9Ydom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(tfidf.vocabulary_)[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4tj5z3OX2Zz",
        "outputId": "aa06ddf3-aa87-410f-d15a-1421f60f680f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['objaw',\n",
              " 'charakterystyczny',\n",
              " 'koronawiruso',\n",
              " 'objaw charakterystyczny',\n",
              " 'charakterystyczny koronawiruso',\n",
              " 'zrobić',\n",
              " 'przypadek',\n",
              " 'wystąpić',\n",
              " 'duszność',\n",
              " 'trudność',\n",
              " 'oddychanie',\n",
              " 'zrobić przypadek',\n",
              " 'przypadek wystąpić',\n",
              " 'wystąpić duszność',\n",
              " 'duszność trudność',\n",
              " 'trudność oddychanie',\n",
              " 'COVID',\n",
              " '19',\n",
              " 'powinien być',\n",
              " 'pierwszy',\n",
              " 'kolejność',\n",
              " 'charakterystyczny COVID',\n",
              " 'COVID 19',\n",
              " '19 powinien być',\n",
              " 'powinien być zrobić',\n",
              " 'zrobić pierwszy',\n",
              " 'pierwszy kolejność',\n",
              " 'móc',\n",
              " 'skontaktować',\n",
              " 'swój',\n",
              " 'lekarz',\n",
              " 'POZ',\n",
              " 'móc skontaktować',\n",
              " 'skontaktować swój',\n",
              " 'swój lekarz',\n",
              " 'lekarz POZ',\n",
              " 'POZ zrobić',\n",
              " 'dyżurować',\n",
              " 'objawy',\n",
              " 'POZ dyżurować',\n",
              " 'dyżurować objawy',\n",
              " 'objawy COVID',\n",
              " '19 zrobić',\n",
              " 'skierować',\n",
              " 'test',\n",
              " 'wystawić',\n",
              " 'nocny',\n",
              " 'świąteczny',\n",
              " 'telepomoc',\n",
              " 'skierowanie',\n",
              " 'skierować test',\n",
              " 'test wystawić',\n",
              " 'wystawić lekarz',\n",
              " 'POZ lekarz',\n",
              " 'lekarz nocny',\n",
              " 'nocny świąteczny',\n",
              " 'świąteczny telepomoc',\n",
              " 'telepomoc wystawić',\n",
              " 'wystawić skierowanie',\n",
              " 'znaleźć',\n",
              " 'wynik',\n",
              " 'znaleźć wynik',\n",
              " 'wynik test',\n",
              " 'pozytywny',\n",
              " 'zostana',\n",
              " 'poinformować',\n",
              " 'test pozytywny',\n",
              " 'pozytywny zostana',\n",
              " 'zostana poinformować',\n",
              " 'skontaktować być',\n",
              " 'sanepidem',\n",
              " 'pomoc',\n",
              " 'formularz',\n",
              " 'strona',\n",
              " 'dostać',\n",
              " 'odpowiedź',\n",
              " 'pytanie',\n",
              " 'skontaktować być sanepidem',\n",
              " 'sanepidem pomoc',\n",
              " 'pomoc formularz',\n",
              " 'formularz strona',\n",
              " 'strona dostać',\n",
              " 'dostać odpowiedź',\n",
              " 'odpowiedź pytanie',\n",
              " 'znaczyć',\n",
              " 'mieć być',\n",
              " 'bliski',\n",
              " 'kontakt',\n",
              " 'osoba',\n",
              " 'chory',\n",
              " 'znaczyć mieć być',\n",
              " 'mieć być bliski',\n",
              " 'bliski kontakt',\n",
              " 'kontakt osoba',\n",
              " 'osoba chory',\n",
              " 'otrzymać',\n",
              " 'zgłosić',\n",
              " 'osoba otrzymać',\n",
              " 'otrzymać pozytywny',\n",
              " 'pozytywny wynik']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf_sim(vectorizer, docs_tfidf, query):\n",
        "    query_tfidf = vectorizer.transform([query])\n",
        "    cosineSimilarities = cosine_similarity(query_tfidf, docs_tfidf).flatten()\n",
        "    return cosineSimilarities"
      ],
      "metadata": {
        "id": "9tOgLRkrYta9"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_sim_index = get_tfidf_sim(tfidf, tfidf_docs_arr, question).argmax()\n",
        "\n",
        "matched_question = df[\"Q\"].iloc[min_distance_vector_index]\n",
        "matched_answer = df[\"A\"].iloc[min_distance_vector_index]\n",
        "print_answer(question, matched_question, matched_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtKdeLYLZ6Xa",
        "outputId": "639299a9-3b7d-49ea-a63e-21f72e4645c0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT QUESTION: Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu się koronawirusa?\n",
            "MATCHED DB QUESTION: Jak zdezynfekować pomieszczenia w zakładzie pracy, w którym przebywała osoba chora lub podejrzana o zachorowanie na koronawirusa? Kto powinien potwierdzić, że ta dezynfekcja miała miejsce?\n",
            "ANSWER: Osoba odpowiedzialna za dezynfekcję pomieszczenia oraz sposób jej dokumentacji powinna być określona przez pracodawcę. W sprawie dezynfekcji pomieszczenia możemy posiłkować się wytycznymi GIS dla POZ (dotyczące dezynfekcji pomieszczenia, w której przebywała osoba chora lub podejrzana o zachorowanie na koronawirusa), tj. wyłączyć z funkcjonowania pomieszczenie, w którym przebywała osoba zakażona, umyć i zdezynfekować powierzchnie, meble, sprzęt – po dezynfekcji może być ponownie używane, wywietrzyć pomieszczenie, w którym przebywała osoba zakażona, zdezynfekować drogę lub drogi dojścia do pomieszczenia gdzie przebywała osoba zakażona do pomieszczenia (poręcze schodów, klamki, lady itp., czyli elementy, których mogła dotykać), używać środków dezynfekujących aktywnych przeciwko wirusom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wygląda na to, że musimy dodać wszystkie określenia koronawirusa do stopwordsów bo algorytm jest na nie zbyt wrażliwy"
      ],
      "metadata": {
        "id": "dYQ1djm9d4nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domain_specific_stopwords = [\n",
        "    \"koronawiruso\",\n",
        "    \"COVID\",\n",
        "    \"19\"\n",
        "]"
      ],
      "metadata": {
        "id": "p4YQwtVgd4TU"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Pomijamy wbudowany preprocesor i użyjemy uni- i bigramów żeby oszukać i przemycić trochę semantyki dystrybucyjnej ;)\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), tokenizer=preprocess, stop_words=domain_specific_stopwords, lowercase=False)    \n",
        "tfidf_docs_arr = tfidf.fit_transform(df[\"Q\"])"
      ],
      "metadata": {
        "id": "JwVA4nvMgJ-x"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(tfidf.vocabulary_)[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkUDlCxhgRuR",
        "outputId": "5f74cc89-4d11-4396-d6f1-9dc3a5d00a75"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['objaw',\n",
              " 'charakterystyczny',\n",
              " 'objaw charakterystyczny',\n",
              " 'zrobić',\n",
              " 'przypadek',\n",
              " 'wystąpić',\n",
              " 'duszność',\n",
              " 'trudność',\n",
              " 'oddychanie',\n",
              " 'zrobić przypadek',\n",
              " 'przypadek wystąpić',\n",
              " 'wystąpić duszność',\n",
              " 'duszność trudność',\n",
              " 'trudność oddychanie',\n",
              " 'powinien być',\n",
              " 'pierwszy',\n",
              " 'kolejność',\n",
              " 'charakterystyczny powinien być',\n",
              " 'powinien być zrobić',\n",
              " 'zrobić pierwszy',\n",
              " 'pierwszy kolejność',\n",
              " 'móc',\n",
              " 'skontaktować',\n",
              " 'swój',\n",
              " 'lekarz',\n",
              " 'POZ',\n",
              " 'móc skontaktować',\n",
              " 'skontaktować swój',\n",
              " 'swój lekarz',\n",
              " 'lekarz POZ',\n",
              " 'POZ zrobić',\n",
              " 'dyżurować',\n",
              " 'objawy',\n",
              " 'POZ dyżurować',\n",
              " 'dyżurować objawy',\n",
              " 'objawy zrobić',\n",
              " 'skierować',\n",
              " 'test',\n",
              " 'wystawić',\n",
              " 'nocny',\n",
              " 'świąteczny',\n",
              " 'telepomoc',\n",
              " 'skierowanie',\n",
              " 'skierować test',\n",
              " 'test wystawić',\n",
              " 'wystawić lekarz',\n",
              " 'POZ lekarz',\n",
              " 'lekarz nocny',\n",
              " 'nocny świąteczny',\n",
              " 'świąteczny telepomoc',\n",
              " 'telepomoc wystawić',\n",
              " 'wystawić skierowanie',\n",
              " 'znaleźć',\n",
              " 'wynik',\n",
              " 'znaleźć wynik',\n",
              " 'wynik test',\n",
              " 'pozytywny',\n",
              " 'zostana',\n",
              " 'poinformować',\n",
              " 'test pozytywny',\n",
              " 'pozytywny zostana',\n",
              " 'zostana poinformować',\n",
              " 'skontaktować być',\n",
              " 'sanepidem',\n",
              " 'pomoc',\n",
              " 'formularz',\n",
              " 'strona',\n",
              " 'dostać',\n",
              " 'odpowiedź',\n",
              " 'pytanie',\n",
              " 'skontaktować być sanepidem',\n",
              " 'sanepidem pomoc',\n",
              " 'pomoc formularz',\n",
              " 'formularz strona',\n",
              " 'strona dostać',\n",
              " 'dostać odpowiedź',\n",
              " 'odpowiedź pytanie',\n",
              " 'znaczyć',\n",
              " 'mieć być',\n",
              " 'bliski',\n",
              " 'kontakt',\n",
              " 'osoba',\n",
              " 'chory',\n",
              " 'znaczyć mieć być',\n",
              " 'mieć być bliski',\n",
              " 'bliski kontakt',\n",
              " 'kontakt osoba',\n",
              " 'osoba chory',\n",
              " 'otrzymać',\n",
              " 'zgłosić',\n",
              " 'osoba otrzymać',\n",
              " 'otrzymać pozytywny',\n",
              " 'pozytywny wynik',\n",
              " 'test powinien być',\n",
              " 'powinien być zgłosić',\n",
              " 'informacja',\n",
              " 'zostać być',\n",
              " 'objąć',\n",
              " 'kwarantanna',\n",
              " 'zgłoszeć']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(tfidf.vocabulary_)[:100]"
      ],
      "metadata": {
        "id": "nr8gpjFAgXQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_sim_index = get_tfidf_sim(tfidf, tfidf_docs_arr, question).argmax()\n",
        "\n",
        "matched_question = df[\"Q\"].iloc[min_distance_vector_index]\n",
        "matched_answer = df[\"A\"].iloc[min_distance_vector_index]\n",
        "print_answer(question, matched_question, matched_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDHlqF0ugdeV",
        "outputId": "e83360c3-0c38-4e5d-96f1-0560c587b4ba"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT QUESTION: Czy wietrzenie pomieszczenia zapobiega rozprzestrzenianiu się koronawirusa?\n",
            "MATCHED DB QUESTION: Jak zdezynfekować pomieszczenia w zakładzie pracy, w którym przebywała osoba chora lub podejrzana o zachorowanie na koronawirusa? Kto powinien potwierdzić, że ta dezynfekcja miała miejsce?\n",
            "ANSWER: Osoba odpowiedzialna za dezynfekcję pomieszczenia oraz sposób jej dokumentacji powinna być określona przez pracodawcę. W sprawie dezynfekcji pomieszczenia możemy posiłkować się wytycznymi GIS dla POZ (dotyczące dezynfekcji pomieszczenia, w której przebywała osoba chora lub podejrzana o zachorowanie na koronawirusa), tj. wyłączyć z funkcjonowania pomieszczenie, w którym przebywała osoba zakażona, umyć i zdezynfekować powierzchnie, meble, sprzęt – po dezynfekcji może być ponownie używane, wywietrzyć pomieszczenie, w którym przebywała osoba zakażona, zdezynfekować drogę lub drogi dojścia do pomieszczenia gdzie przebywała osoba zakażona do pomieszczenia (poręcze schodów, klamki, lady itp., czyli elementy, których mogła dotykać), używać środków dezynfekujących aktywnych przeciwko wirusom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Powinno być troszkę lepiej. :)\n",
        "\n",
        "Możemy teraz porównać sobie nasze dwa rozwiązania uznając, że to oparte o TF-IDF jest benchmarkiem. brakuje nam zbioru danych i miary ale możemy potestować ręcznie.\n",
        "\n",
        "Skoro obydwa rozwiązania mają swoje wady i zalety, które dodatkowo różnią się między sobą, czemu nie pozwolić im współpracować korzystając faktu, że np. zespół słabych klasyfikatorów osiąga dużo lepsze wyniki niż każdy z osobna.\n",
        "\n",
        "Sprawdźmy jak będzie działało rozwiązanie, które łączyło będzie wyniki kilku rozwiązań poprzez proste głosowanie większościowe (jak np. w modelach random forest).\n",
        "\n"
      ],
      "metadata": {
        "id": "6BpNcCe1giKg"
      }
    }
  ]
}